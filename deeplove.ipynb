{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37314199",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-27T07:08:16.222863Z",
     "iopub.status.busy": "2024-05-27T07:08:16.222512Z",
     "iopub.status.idle": "2024-05-27T07:08:31.263871Z",
     "shell.execute_reply": "2024-05-27T07:08:31.262442Z"
    },
    "papermill": {
     "duration": 15.049166,
     "end_time": "2024-05-27T07:08:31.266141",
     "exception": false,
     "start_time": "2024-05-27T07:08:16.216975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 07:08:19.177775: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-27 07:08:19.177886: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-27 07:08:19.351450: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff62dd7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T07:08:31.280885Z",
     "iopub.status.busy": "2024-05-27T07:08:31.279190Z",
     "iopub.status.idle": "2024-05-27T07:08:32.478420Z",
     "shell.execute_reply": "2024-05-27T07:08:32.477500Z"
    },
    "papermill": {
     "duration": 1.207075,
     "end_time": "2024-05-27T07:08:32.480918",
     "exception": false,
     "start_time": "2024-05-27T07:08:31.273843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "csv_file_path = '/kaggle/input/rsna-bone-age/boneage-training-dataset.csv'\n",
    "dataset_path = '/kaggle/input/rsna-bone-age/boneage-training-dataset/boneage-training-dataset'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Filter the dataset based on conditions\n",
    "ra = []\n",
    "for i in range(187):\n",
    "    if i % 12 == 5 or i % 12 == 6 or i % 12 == 7:\n",
    "        ra.append(i)\n",
    "\n",
    "id_to_bone_age = {row['id']: row['boneage'] for _, row in df.iterrows()}\n",
    "\n",
    "selected_ids = [int(file_name.split('.')[0]) for file_name in os.listdir(dataset_path) if file_name.split('.')[0].isdigit()]\n",
    "filtered_ids = [id for id in selected_ids if id_to_bone_age[id] in ra]\n",
    "\n",
    "image_paths = [os.path.join(dataset_path, f\"{id}.png\") for id in filtered_ids]\n",
    "ages = [id_to_bone_age[id] // 12 for id in filtered_ids]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train_paths, X_test_paths, y_train, y_test = train_test_split(\n",
    "    image_paths, ages, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "414e604e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T07:08:32.490489Z",
     "iopub.status.busy": "2024-05-27T07:08:32.489993Z",
     "iopub.status.idle": "2024-05-27T07:08:33.284534Z",
     "shell.execute_reply": "2024-05-27T07:08:33.283707Z"
    },
    "papermill": {
     "duration": 0.801998,
     "end_time": "2024-05-27T07:08:33.287115",
     "exception": false,
     "start_time": "2024-05-27T07:08:32.485117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "id_to_bone_age = {row['id']: row['boneage'] for _, row in df.iterrows()}\n",
    "image_paths = []\n",
    "ages = []\n",
    "\n",
    "for file_name in os.listdir(dataset_path):\n",
    "    file_path = os.path.join(dataset_path, file_name)\n",
    "    idf=file_name.split('.')[0]\n",
    "    if(idf.isdigit()):\n",
    "      if(id_to_bone_age[int(idf)] in ra ):\n",
    "\n",
    "        image_paths.append(file_path)\n",
    "        ages.append(id_to_bone_age[int(file_name.split('.')[0])]//12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1cdf1c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T07:08:33.297038Z",
     "iopub.status.busy": "2024-05-27T07:08:33.296368Z",
     "iopub.status.idle": "2024-05-27T07:08:33.304699Z",
     "shell.execute_reply": "2024-05-27T07:08:33.303731Z"
    },
    "papermill": {
     "duration": 0.015131,
     "end_time": "2024-05-27T07:08:33.306581",
     "exception": false,
     "start_time": "2024-05-27T07:08:33.291450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/kaggle/input/rsna-bone-age/boneage-training-dataset/boneage-training-dataset/9273.png'\n",
      " '/kaggle/input/rsna-bone-age/boneage-training-dataset/boneage-training-dataset/14127.png'\n",
      " '/kaggle/input/rsna-bone-age/boneage-training-dataset/boneage-training-dataset/11396.png'\n",
      " ...\n",
      " '/kaggle/input/rsna-bone-age/boneage-training-dataset/boneage-training-dataset/6995.png'\n",
      " '/kaggle/input/rsna-bone-age/boneage-training-dataset/boneage-training-dataset/14760.png'\n",
      " '/kaggle/input/rsna-bone-age/boneage-training-dataset/boneage-training-dataset/4225.png']\n",
      "[12 14  4 ... 11 13 12]\n",
      "2921 2921\n"
     ]
    }
   ],
   "source": [
    "image_paths = np.array(image_paths)\n",
    "ages = np.array(ages)\n",
    "print(image_paths)\n",
    "print(ages)\n",
    "print(len(image_paths),len(ages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73bcfa28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T07:08:33.315990Z",
     "iopub.status.busy": "2024-05-27T07:08:33.315662Z",
     "iopub.status.idle": "2024-05-27T07:08:33.322816Z",
     "shell.execute_reply": "2024-05-27T07:08:33.321882Z"
    },
    "papermill": {
     "duration": 0.01413,
     "end_time": "2024-05-27T07:08:33.324766",
     "exception": false,
     "start_time": "2024-05-27T07:08:33.310636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 2 occurrences\n",
      "1: 29 occurrences\n",
      "2: 39 occurrences\n",
      "3: 90 occurrences\n",
      "4: 101 occurrences\n",
      "5: 44 occurrences\n",
      "6: 56 occurrences\n",
      "7: 51 occurrences\n",
      "8: 51 occurrences\n",
      "9: 116 occurrences\n",
      "10: 204 occurrences\n",
      "11: 536 occurrences\n",
      "12: 681 occurrences\n",
      "13: 685 occurrences\n",
      "14: 98 occurrences\n",
      "15: 138 occurrences\n"
     ]
    }
   ],
   "source": [
    "unique_values, counts = np.unique(ages, return_counts=True)\n",
    "\n",
    "# Display the value counts\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"{value}: {count} occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e563623",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T07:08:33.334334Z",
     "iopub.status.busy": "2024-05-27T07:08:33.334041Z",
     "iopub.status.idle": "2024-05-27T07:08:33.345355Z",
     "shell.execute_reply": "2024-05-27T07:08:33.344555Z"
    },
    "papermill": {
     "duration": 0.018558,
     "end_time": "2024-05-27T07:08:33.347436",
     "exception": false,
     "start_time": "2024-05-27T07:08:33.328878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for value, count in zip(unique_values, counts):\n",
    "    if count < 75:\n",
    "        # Augment the data to reach 75 occurrences\n",
    "        augmentation_factor = int(np.ceil(75 / count))\n",
    "        indices = np.where(ages == value)[0]\n",
    "\n",
    "        # Augment the data by replicating images\n",
    "        augmented_paths = np.repeat(np.array(image_paths)[indices], augmentation_factor)\n",
    "        augmented_ages = np.repeat(value, len(augmented_paths))\n",
    "\n",
    "        # Update the dataset\n",
    "        image_paths = np.concatenate([image_paths, augmented_paths])\n",
    "        ages = np.concatenate([ages, augmented_ages])\n",
    "\n",
    "# Split the augmented dataset into training and testing sets\n",
    "X_train_paths, X_test_paths, y_train, y_test = train_test_split(\n",
    "    image_paths, ages, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1ddee0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T07:08:33.357025Z",
     "iopub.status.busy": "2024-05-27T07:08:33.356739Z",
     "iopub.status.idle": "2024-05-27T07:08:33.362762Z",
     "shell.execute_reply": "2024-05-27T07:08:33.361745Z"
    },
    "papermill": {
     "duration": 0.013154,
     "end_time": "2024-05-27T07:08:33.364828",
     "exception": false,
     "start_time": "2024-05-27T07:08:33.351674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 78 occurrences\n",
      "1: 116 occurrences\n",
      "2: 117 occurrences\n",
      "3: 90 occurrences\n",
      "4: 101 occurrences\n",
      "5: 132 occurrences\n",
      "6: 168 occurrences\n",
      "7: 153 occurrences\n",
      "8: 153 occurrences\n",
      "9: 116 occurrences\n",
      "10: 204 occurrences\n",
      "11: 536 occurrences\n",
      "12: 681 occurrences\n",
      "13: 685 occurrences\n",
      "14: 98 occurrences\n",
      "15: 138 occurrences\n"
     ]
    }
   ],
   "source": [
    "unique_values, counts = np.unique(ages, return_counts=True)\n",
    "\n",
    "# Display the value counts\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"{value}: {count} occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab4dd09e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T07:08:33.374233Z",
     "iopub.status.busy": "2024-05-27T07:08:33.373717Z",
     "iopub.status.idle": "2024-05-27T07:11:03.872932Z",
     "shell.execute_reply": "2024-05-27T07:11:03.872023Z"
    },
    "papermill": {
     "duration": 150.558284,
     "end_time": "2024-05-27T07:11:03.927296",
     "exception": false,
     "start_time": "2024-05-27T07:08:33.369012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and Preprocessing Images: 100%|██████████| 2852/2852 [02:01<00:00, 23.45it/s]\n",
      "Loading and Preprocessing Images: 100%|██████████| 714/714 [00:28<00:00, 25.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess images\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "def preprocess_images(image_paths, target_size=(224, 224)):\n",
    "    images = []\n",
    "    for path in tqdm(image_paths, desc='Loading and Preprocessing Images'):\n",
    "        img = image.load_img(path, target_size=target_size)\n",
    "        img = image.img_to_array(img)  # Convert PIL Image to NumPy array\n",
    "        img = cv2.cvtColor(img.astype('uint8'), cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "        img = cv2.equalizeHist(img.astype('uint8'))\n",
    "        img_array = np.expand_dims(img, axis=0)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        images.append(img_array)\n",
    "    return np.vstack(images)\n",
    "\n",
    "X_train = preprocess_images(X_train_paths)\n",
    "X_test = preprocess_images(X_test_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a200315",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T07:11:04.117708Z",
     "iopub.status.busy": "2024-05-27T07:11:04.117316Z",
     "iopub.status.idle": "2024-05-27T07:21:22.576382Z",
     "shell.execute_reply": "2024-05-27T07:21:22.575353Z"
    },
    "papermill": {
     "duration": 618.559792,
     "end_time": "2024-05-27T07:21:22.578497",
     "exception": false,
     "start_time": "2024-05-27T07:11:04.018705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m83683744/83683744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1716794058.341719      74 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "W0000 00:00:1716794058.414362      74 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663ms/step - loss: 17.7350 - mae: 2.8969"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1716794117.746858      74 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n",
      "W0000 00:00:1716794121.810619      71 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 805ms/step - loss: 17.6179 - mae: 2.8851 - val_loss: 75.8173 - val_mae: 8.1081\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1716794130.437867      74 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 433ms/step - loss: 1.6329 - mae: 1.0071 - val_loss: 12.4382 - val_mae: 3.0892\n",
      "Epoch 3/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 429ms/step - loss: 1.2830 - mae: 0.9018 - val_loss: 2.3920 - val_mae: 1.2380\n",
      "Epoch 4/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 430ms/step - loss: 0.7577 - mae: 0.6834 - val_loss: 2.7782 - val_mae: 1.3386\n",
      "Epoch 5/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 430ms/step - loss: 0.6386 - mae: 0.6153 - val_loss: 1.1450 - val_mae: 0.7838\n",
      "Epoch 6/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 430ms/step - loss: 0.6244 - mae: 0.6291 - val_loss: 1.3987 - val_mae: 0.9107\n",
      "Epoch 7/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 430ms/step - loss: 0.6789 - mae: 0.6581 - val_loss: 4.1287 - val_mae: 1.7488\n",
      "Epoch 8/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 430ms/step - loss: 0.6024 - mae: 0.6194 - val_loss: 0.9234 - val_mae: 0.6833\n",
      "Epoch 9/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 430ms/step - loss: 0.7183 - mae: 0.6859 - val_loss: 1.9858 - val_mae: 1.1555\n",
      "Epoch 10/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 429ms/step - loss: 0.5015 - mae: 0.5601 - val_loss: 0.9919 - val_mae: 0.7139\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 0.9056 - mae: 0.6824\n",
      "Test MAE: 0.7138898968696594\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import cv2\n",
    "\n",
    "# Load the pre-trained Xception model (excluding the top layers)\n",
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom layers on top\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(1, activation='linear')(x)  # Regression output\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Load and preprocess images (convert to RGB)\n",
    "def preprocess_images(image_paths, target_size=(224, 224)):\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = load_img(path, target_size=target_size)\n",
    "        img = img_to_array(img)\n",
    "        img = cv2.cvtColor(img.astype('uint8'), cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "        img_array = np.expand_dims(img, axis=0)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        images.append(img_array)\n",
    "    return np.vstack(images)\n",
    "\n",
    "X_train_rgb = preprocess_images(X_train_paths)\n",
    "X_test_rgb = preprocess_images(X_test_paths)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_rgb, y_train, validation_data=(X_test_rgb, y_test), epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_mae = model.evaluate(X_test_rgb, y_test)\n",
    "print(f\"Test MAE: {test_mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcef023c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T07:21:22.929675Z",
     "iopub.status.busy": "2024-05-27T07:21:22.929277Z",
     "iopub.status.idle": "2024-05-27T07:21:23.674147Z",
     "shell.execute_reply": "2024-05-27T07:21:23.672932Z"
    },
    "papermill": {
     "duration": 0.92493,
     "end_time": "2024-05-27T07:21:23.675914",
     "exception": true,
     "start_time": "2024-05-27T07:21:22.750984",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Plot training & validation loss values\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Plot training & validation accuracy values (if available)\n",
    "if 'accuracy' in history.history:\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b5130d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 10832,
     "sourceId": 15122,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 793.687751,
   "end_time": "2024-05-27T07:21:26.927738",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-27T07:08:13.239987",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
