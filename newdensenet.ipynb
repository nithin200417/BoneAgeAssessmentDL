{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3e507ce",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-12T01:47:24.678911Z",
     "iopub.status.busy": "2024-07-12T01:47:24.678201Z",
     "iopub.status.idle": "2024-07-12T01:47:41.747874Z",
     "shell.execute_reply": "2024-07-12T01:47:41.747049Z"
    },
    "papermill": {
     "duration": 17.076295,
     "end_time": "2024-07-12T01:47:41.750039",
     "exception": false,
     "start_time": "2024-07-12T01:47:24.673744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 01:47:27.518002: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-12 01:47:27.518103: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-12 01:47:27.680893: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import Sequential\n",
    "from keras.metrics import mean_absolute_error\n",
    "\n",
    "#loading dataframes\n",
    "train_df = pd.read_csv('/kaggle/input/rsna-bone-age/boneage-training-dataset.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/rsna-bone-age/boneage-test-dataset.csv')\n",
    "\n",
    "#appending file extension to id column for both training and testing dataframes\n",
    "train_df['id'] = train_df['id'].apply(lambda x: str(x)+'.png')\n",
    "test_df['Case ID'] = test_df['Case ID'].apply(lambda x: str(x)+'.png') \n",
    "\n",
    "#models perform better when features are normalised to have zero mean and unity standard deviation\n",
    "#using z score for the training\n",
    "mean_bone_age = train_df['boneage'].mean()\n",
    "std_bone_age = train_df['boneage'].std()\n",
    "train_df['bone_age_z'] = (train_df['boneage'] - mean_bone_age)/(std_bone_age)\n",
    "\n",
    "# Define the age ranges\n",
    "ages = train_df['boneage'].values\n",
    "image_paths = train_df['id'].values\n",
    "max_age = max(ages)\n",
    "age_ranges = [(i, i+1) for i in range(0, max_age+1)]\n",
    "\n",
    "for lower_bound, upper_bound in age_ranges:\n",
    "    # Calculate the localized mean for the current age range\n",
    "    localized_mean = np.mean([age for age in ages if lower_bound <= age < upper_bound])\n",
    "\n",
    "    for value in range(lower_bound, upper_bound):\n",
    "        count = np.count_nonzero(ages == value)\n",
    "\n",
    "        if count < 75:\n",
    "            # Calculate the augmentation factor\n",
    "            augmentation_factor = int(np.ceil(75 / count)) if count > 0 else 75\n",
    "\n",
    "            # Get the indices of the images corresponding to the current age\n",
    "            indices = [i for i, age in enumerate(ages) if age == value]\n",
    "\n",
    "            # Augment the data by replicating images\n",
    "            augmented_paths = np.repeat(np.array(image_paths)[indices], augmentation_factor)\n",
    "            augmented_ages = np.full(len(augmented_paths), localized_mean)\n",
    "\n",
    "            # Update the dataset\n",
    "            image_paths = np.concatenate([image_paths, augmented_paths])\n",
    "            ages = np.concatenate([ages, augmented_ages])\n",
    "\n",
    "# Split the augmented dataset into training and testing sets\n",
    "X_train_paths, X_test_paths, y_train, y_test = train_test_split(\n",
    "    image_paths, ages, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c19c8d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T01:47:41.757684Z",
     "iopub.status.busy": "2024-07-12T01:47:41.757027Z",
     "iopub.status.idle": "2024-07-12T01:48:04.458046Z",
     "shell.execute_reply": "2024-07-12T01:48:04.457311Z"
    },
    "papermill": {
     "duration": 22.706785,
     "end_time": "2024-07-12T01:48:04.460085",
     "exception": false,
     "start_time": "2024-07-12T01:47:41.753300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10331 validated image filenames.\n",
      "Found 3111 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "img_size = 256\n",
    "data_augmentation = dict(rotation_range=0.2, zoom_range=0.1, horizontal_flip=True,\n",
    "                                width_shift_range=0.05,\n",
    "                                height_shift_range=0.05,\n",
    "                                shear_range=0.05, fill_mode='nearest')\n",
    "# Define the data generators\n",
    "train_data_generator = ImageDataGenerator(preprocessing_function = tf.keras.applications.xception.preprocess_input,  **data_augmentation)\n",
    "val_data_generator = ImageDataGenerator(preprocessing_function = tf.keras.applications.xception.preprocess_input)\n",
    "\n",
    "# Define the generators\n",
    "train_generator = train_data_generator.flow_from_dataframe(\n",
    "    dataframe = train_df[train_df['id'].isin(X_train_paths)],\n",
    "    directory = '/kaggle/input/rsna-bone-age/boneage-training-dataset/boneage-training-dataset',\n",
    "    x_col= 'id',\n",
    "    y_col= 'bone_age_z',\n",
    "    batch_size = 32,\n",
    "    seed = 42,\n",
    "    shuffle = True,\n",
    "    class_mode= 'other',\n",
    "    flip_vertical = True,\n",
    "    color_mode = 'rgb',\n",
    "    target_size = (img_size, img_size))\n",
    "\n",
    "val_generator = val_data_generator.flow_from_dataframe(\n",
    "    dataframe = train_df[train_df['id'].isin(X_test_paths)],\n",
    "    directory = '/kaggle/input/rsna-bone-age/boneage-training-dataset/boneage-training-dataset',\n",
    "    x_col = 'id',\n",
    "    y_col = 'bone_age_z',\n",
    "    batch_size = 32,\n",
    "    seed = 42,\n",
    "    shuffle = True,\n",
    "    class_mode = 'other',\n",
    "    flip_vertical = True,\n",
    "    color_mode = 'rgb',\n",
    "    target_size = (img_size, img_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "794e4bda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T01:48:04.467786Z",
     "iopub.status.busy": "2024-07-12T01:48:04.467482Z",
     "iopub.status.idle": "2024-07-12T04:45:23.169462Z",
     "shell.execute_reply": "2024-07-12T04:45:23.168346Z"
    },
    "papermill": {
     "duration": 10638.709022,
     "end_time": "2024-07-12T04:45:23.172422",
     "exception": false,
     "start_time": "2024-07-12T01:48:04.463400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m74836368/74836368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1720749239.247986      70 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "W0000 00:00:1720749239.532581      70 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 30/315\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:32\u001b[0m 2s/step - loss: 5.2959 - mae_in_months: 67.4005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1720749499.578318      71 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 1.4125 - mae_in_months: 31.6425"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1720749984.231426      73 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1094s\u001b[0m 2s/step - loss: 1.4099 - mae_in_months: 31.6116 - val_loss: 0.2730 - val_mae_in_months: 18.0259 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.2492 - mae_in_months: 16.6489 - val_loss: 0.3432 - val_mae_in_months: 19.1523 - learning_rate: 0.0010\n",
      "Epoch 3/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 1s/step - loss: 0.2110 - mae_in_months: 14.8501 - val_loss: 0.1588 - val_mae_in_months: 12.5494 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2085 - mae_in_months: 14.8831 - val_loss: 0.2650 - val_mae_in_months: 16.2217 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 1s/step - loss: 0.1689 - mae_in_months: 13.3827 - val_loss: 0.1693 - val_mae_in_months: 13.0656 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.1580 - mae_in_months: 13.2547 - val_loss: 0.1708 - val_mae_in_months: 13.4857 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 1s/step - loss: 0.1536 - mae_in_months: 12.7899 - val_loss: 0.1356 - val_mae_in_months: 13.0091 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1340 - mae_in_months: 12.1138 - val_loss: 0.1378 - val_mae_in_months: 12.0793 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 1s/step - loss: 0.1353 - mae_in_months: 12.0272 - val_loss: 0.1160 - val_mae_in_months: 10.7791 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1241 - mae_in_months: 11.4301 - val_loss: 0.1496 - val_mae_in_months: 12.4472 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 1s/step - loss: 0.1307 - mae_in_months: 11.6631 - val_loss: 0.1286 - val_mae_in_months: 12.0925 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - loss: 0.1422 - mae_in_months: 12.7438 - val_loss: 0.0961 - val_mae_in_months: 10.4834 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 1s/step - loss: 0.1194 - mae_in_months: 11.3372 - val_loss: 0.0781 - val_mae_in_months: 8.7910 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.1247 - mae_in_months: 11.3325 - val_loss: 0.2056 - val_mae_in_months: 15.9236 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 1s/step - loss: 0.1129 - mae_in_months: 10.9023 - val_loss: 0.1294 - val_mae_in_months: 11.9884 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.1235 - mae_in_months: 11.2228 - val_loss: 0.2235 - val_mae_in_months: 15.5203 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 1s/step - loss: 0.1089 - mae_in_months: 10.7724 - val_loss: 0.1452 - val_mae_in_months: 11.6936 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.1182 - mae_in_months: 10.8424 - val_loss: 0.1720 - val_mae_in_months: 13.8167 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 1s/step - loss: 0.1052 - mae_in_months: 10.5411 - val_loss: 0.0933 - val_mae_in_months: 9.6912 - learning_rate: 0.0010\n",
      "Epoch 20/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.1281 - mae_in_months: 11.4091 - val_loss: 0.1372 - val_mae_in_months: 12.2487 - learning_rate: 0.0010\n",
      "Epoch 21/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 1s/step - loss: 0.1024 - mae_in_months: 10.3405 - val_loss: 0.0714 - val_mae_in_months: 8.9126 - learning_rate: 0.0010\n",
      "Epoch 22/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1346 - mae_in_months: 11.9025 - val_loss: 0.1493 - val_mae_in_months: 12.9938 - learning_rate: 0.0010\n",
      "Epoch 23/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 1s/step - loss: 0.0993 - mae_in_months: 10.2428 - val_loss: 0.2400 - val_mae_in_months: 16.0301 - learning_rate: 0.0010\n",
      "Epoch 24/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.1282 - mae_in_months: 11.5810 - val_loss: 0.1093 - val_mae_in_months: 12.0894 - learning_rate: 0.0010\n",
      "Epoch 25/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 1s/step - loss: 0.1028 - mae_in_months: 10.3585 - val_loss: 0.2039 - val_mae_in_months: 15.2055 - learning_rate: 0.0010\n",
      "Epoch 26/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - loss: 0.0873 - mae_in_months: 9.8187 - val_loss: 0.0683 - val_mae_in_months: 8.2981 - learning_rate: 0.0010\n",
      "Epoch 27/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 1s/step - loss: 0.0941 - mae_in_months: 9.9407 - val_loss: 0.0799 - val_mae_in_months: 9.6029 - learning_rate: 0.0010\n",
      "Epoch 28/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0976 - mae_in_months: 10.3922 - val_loss: 0.1600 - val_mae_in_months: 13.9181 - learning_rate: 0.0010\n",
      "Epoch 29/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 1s/step - loss: 0.0943 - mae_in_months: 9.9355 - val_loss: 0.1156 - val_mae_in_months: 10.6537 - learning_rate: 0.0010\n",
      "Epoch 30/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0890 - mae_in_months: 9.8394 - val_loss: 0.2261 - val_mae_in_months: 15.4775 - learning_rate: 0.0010\n",
      "Epoch 31/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 1s/step - loss: 0.0875 - mae_in_months: 9.6036 - val_loss: 0.1332 - val_mae_in_months: 11.8328 - learning_rate: 0.0010\n",
      "Epoch 32/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0943 - mae_in_months: 9.7178 - val_loss: 0.1233 - val_mae_in_months: 11.8869 - learning_rate: 0.0010\n",
      "Epoch 33/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 1s/step - loss: 0.0987 - mae_in_months: 10.0709 - val_loss: 0.1376 - val_mae_in_months: 12.0732 - learning_rate: 0.0010\n",
      "Epoch 34/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - loss: 0.0972 - mae_in_months: 10.3254 - val_loss: 0.0459 - val_mae_in_months: 6.8534 - learning_rate: 0.0010\n",
      "Epoch 35/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 1s/step - loss: 0.0853 - mae_in_months: 9.4436 - val_loss: 0.0784 - val_mae_in_months: 9.4419 - learning_rate: 0.0010\n",
      "Epoch 36/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0837 - mae_in_months: 9.1960 - val_loss: 0.0966 - val_mae_in_months: 10.6698 - learning_rate: 0.0010\n",
      "Epoch 37/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m435s\u001b[0m 1s/step - loss: 0.0796 - mae_in_months: 9.1132 - val_loss: 0.1604 - val_mae_in_months: 13.2894 - learning_rate: 0.0010\n",
      "Epoch 38/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0893 - mae_in_months: 9.6698 - val_loss: 0.1416 - val_mae_in_months: 12.4532 - learning_rate: 0.0010\n",
      "Epoch 39/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 1s/step - loss: 0.0764 - mae_in_months: 8.9561 - val_loss: 0.0827 - val_mae_in_months: 10.1325 - learning_rate: 0.0010\n",
      "Epoch 40/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0949 - mae_in_months: 9.7953 - val_loss: 0.1135 - val_mae_in_months: 11.3723 - learning_rate: 0.0010\n",
      "Epoch 41/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 1s/step - loss: 0.0798 - mae_in_months: 9.0644 - val_loss: 0.1110 - val_mae_in_months: 9.9904 - learning_rate: 0.0010\n",
      "Epoch 42/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0671 - mae_in_months: 8.5062 - val_loss: 0.2082 - val_mae_in_months: 14.9514 - learning_rate: 0.0010\n",
      "Epoch 43/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 1s/step - loss: 0.0603 - mae_in_months: 7.8748 - val_loss: 0.0761 - val_mae_in_months: 8.9605 - learning_rate: 1.0000e-04\n",
      "Epoch 44/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0527 - mae_in_months: 7.2194 - val_loss: 0.0856 - val_mae_in_months: 8.9551 - learning_rate: 1.0000e-04\n",
      "Epoch 45/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 1s/step - loss: 0.0513 - mae_in_months: 7.3183 - val_loss: 0.0523 - val_mae_in_months: 7.6529 - learning_rate: 1.0000e-04\n",
      "Epoch 46/60\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0459 - mae_in_months: 6.7938 - val_loss: 0.0680 - val_mae_in_months: 8.5575 - learning_rate: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Define the custom metric\n",
    "def mae_in_months(x_p, y_p):\n",
    "    return mean_absolute_error((std_bone_age*x_p + mean_bone_age), (std_bone_age*y_p + mean_bone_age))\n",
    "\n",
    "# Define the data generators\n",
    "train_data_generator = ImageDataGenerator(preprocessing_function = tf.keras.applications.xception.preprocess_input,  **data_augmentation)\n",
    "val_data_generator = ImageDataGenerator(preprocessing_function = tf.keras.applications.xception.preprocess_input)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.applications.DenseNet201(input_shape = (img_size, img_size, 3),\n",
    "                                           include_top = False,\n",
    "                                           weights = 'imagenet')\n",
    "model.trainable = True\n",
    "model = Sequential([model,\n",
    "                    GlobalMaxPooling2D(),\n",
    "                    Flatten(),\n",
    "                    Dense(64, activation = 'relu'),\n",
    "                    Dense(32, activation = 'relu'),\n",
    "                    Dense(1, activation = 'linear')])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss ='mse', optimizer= tf.keras.optimizers.Adamax(learning_rate=0.001), metrics = [mae_in_months])\n",
    "\n",
    "# Define the callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience= 12, verbose=0, mode='auto')\n",
    "mc = ModelCheckpoint('best_model.keras', monitor='val_loss', mode='min', save_best_only=True, save_weights_only = False)\n",
    "red_lr_plat = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=8, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "callbacks = [early_stopping, mc, red_lr_plat]\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(train_generator,\n",
    "                            steps_per_epoch = 315,\n",
    "                            validation_data = val_generator,\n",
    "                            validation_steps = 1,\n",
    "                            epochs = 60,\n",
    "                            callbacks= callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "868b99ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T04:45:24.401951Z",
     "iopub.status.busy": "2024-07-12T04:45:24.401064Z",
     "iopub.status.idle": "2024-07-12T04:45:24.414523Z",
     "shell.execute_reply": "2024-07-12T04:45:24.413647Z"
    },
    "papermill": {
     "duration": 0.618372,
     "end_time": "2024-07-12T04:45:24.416410",
     "exception": false,
     "start_time": "2024-07-12T04:45:23.798038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model.build((None, img_size, img_size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4781d33a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T04:45:25.621189Z",
     "iopub.status.busy": "2024-07-12T04:45:25.620833Z",
     "iopub.status.idle": "2024-07-12T04:45:59.938059Z",
     "shell.execute_reply": "2024-07-12T04:45:59.937229Z"
    },
    "papermill": {
     "duration": 35.53827,
     "end_time": "2024-07-12T04:46:00.558360",
     "exception": false,
     "start_time": "2024-07-12T04:45:25.020090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 33s/step\n",
      "Image 1 predicted age: -2.02 years\n",
      "Image 2 predicted age: 0.16 years\n",
      "Image 3 predicted age: 0.70 years\n",
      "Image 4 predicted age: -0.83 years\n",
      "Image 5 predicted age: 0.85 years\n",
      "Image 6 predicted age: 0.72 years\n",
      "Image 7 predicted age: -1.18 years\n",
      "Image 8 predicted age: 0.64 years\n",
      "Image 9 predicted age: 0.40 years\n",
      "Image 10 predicted age: -1.22 years\n",
      "Image 11 predicted age: -0.56 years\n",
      "Image 12 predicted age: -0.98 years\n",
      "Image 13 predicted age: -0.40 years\n",
      "Image 14 predicted age: 0.33 years\n",
      "Image 15 predicted age: -1.75 years\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1720759559.888469      73 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "image_paths = [os.path.join('/kaggle/input/hand-x-rays/Hand xrays', f\"{file_name}\") for file_name in os.listdir('/kaggle/input/hand-x-rays/Hand xrays')]\n",
    "\n",
    "def load_and_preprocess_images(image_paths, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img, target_size)  # Ensure output shape is (224, 224, 3)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_array = np.expand_dims(img, axis=0)\n",
    "        img_array = preprocess_input(img_array)  # Use DenseNet201's preprocess_input\n",
    "        images.append(img_array)\n",
    "    return np.vstack(images)\n",
    "\n",
    "new_images = load_and_preprocess_images(image_paths)\n",
    "\n",
    "predictions = model.predict(new_images)\n",
    "\n",
    "# Print the predicted ages\n",
    "for i, prediction in enumerate(predictions):\n",
    "    print(f\"Image {i+1} predicted age: {prediction[0]:.2f} years\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14556b92",
   "metadata": {
    "papermill": {
     "duration": 0.600146,
     "end_time": "2024-07-12T04:46:01.758708",
     "exception": false,
     "start_time": "2024-07-12T04:46:01.158562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 10832,
     "sourceId": 15122,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4853257,
     "sourceId": 8194170,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5374918,
     "sourceId": 8934188,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10724.394813,
   "end_time": "2024-07-12T04:46:06.116975",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-12T01:47:21.722162",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
